{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d619df9e-3088-44a9-8405-f08679e9fb24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
    "\n",
    "\n",
    "DATA_DIR = \"#folder path\" # the folder with all .txt files\n",
    "\n",
    "WINDOW_SIZE = 128\n",
    "OVERLAP = 0.5\n",
    "\n",
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def load_gait_files(folder):\n",
    "    X_all = []\n",
    "    y_all = []\n",
    "\n",
    "    files = glob.glob(os.path.join(folder, \"*.txt\"))\n",
    "    print(f\"Found {len(files)} files.\")\n",
    "    if len(files) == 0:\n",
    "        raise ValueError(\"No files found. Check folder path and extensions!\")\n",
    "\n",
    "    for file in files:\n",
    "        df = pd.read_csv(file, sep=\"\\t\", header=None)\n",
    "        # Features: columns 1-18 (ignore column 0 = time)\n",
    "        X = df.iloc[:, 1:19].values\n",
    "\n",
    "        # Assign label based on filename\n",
    "        filename = os.path.basename(file)\n",
    "        if \"Co\" in filename or \"co\" in filename:\n",
    "            label = 0\n",
    "        elif \"Pt\" in filename or \"pt\" in filename:\n",
    "            label = 1\n",
    "        else:\n",
    "            print(\"Skipping unknown file:\", filename)\n",
    "            continue\n",
    "\n",
    "        y = np.full((X.shape[0],), label)\n",
    "\n",
    "        X_all.append(X)\n",
    "        y_all.append(y)\n",
    "\n",
    "    # Combine all files\n",
    "    X_all = np.vstack(X_all)\n",
    "    y_all = np.hstack(y_all)\n",
    "    print(\"Combined shape:\", X_all.shape, y_all.shape)\n",
    "\n",
    "    return X_all, y_all\n",
    "\n",
    "\n",
    "X, y = load_gait_files(DATA_DIR)\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# SEGMENTATION \n",
    "\n",
    "def segment_signal(X, y, window_size=128, overlap=0.5):\n",
    "    step = int(window_size * (1 - overlap))\n",
    "    X_segments, y_segments = [], []\n",
    "\n",
    "    for start in range(0, len(X) - window_size, step):\n",
    "        end = start + window_size\n",
    "        X_segments.append(X[start:end])\n",
    "        y_segments.append(int(round(np.mean(y[start:end]))))\n",
    "\n",
    "    return np.array(X_segments), np.array(y_segments)\n",
    "\n",
    "X_segments, y_segments = segment_signal(X_scaled, y, WINDOW_SIZE, OVERLAP)\n",
    "print(\"Segmented shape:\", X_segments.shape, y_segments.shape)\n",
    "\n",
    "# TRAIN/TEST SPLIT \n",
    "X_train, X_test, y_train, y_test = train_test_split(X_segments, y_segments, test_size=0.2, random_state=42, stratify=y_segments)\n",
    "\n",
    "print(\"Train:\", X_train.shape, \"Test:\", X_test.shape)\n",
    "\n",
    "# CNN MODEL \n",
    "model = Sequential([\n",
    "    Conv1D(64, 3, activation='relu', input_shape=(WINDOW_SIZE, X_segments.shape[2])),\n",
    "    MaxPooling1D(2),\n",
    "    Dropout(0.3),\n",
    "    Conv1D(128, 3, activation='relu'),\n",
    "    MaxPooling1D(2),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(1, activation='sigmoid')  # Binary classification\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "# TRAINING \n",
    "history = model.fit( X_train, y_train,validation_data=(X_test, y_test),epochs=20,batch_size=64)\n",
    "\n",
    "# PLOTTING RESULTS\n",
    "plt.figure(figsize=(12,4))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(history.history['accuracy'], label='Train')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation')\n",
    "plt.title('Model Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(history.history['loss'], label='Train')\n",
    "plt.plot(history.history['val_loss'], label='Validation')\n",
    "plt.title('Model Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# EVALUATE \n",
    "loss, acc = model.evaluate(X_test, y_test)\n",
    "print(f\"\\nTest Accuracy: {acc*100:.2f}% | Test Loss: {loss:.4f}\")\n",
    "\n",
    "# VISUALIZE GAIT WAVES \n",
    "# Example: showing 5 random samples from test set\n",
    "import random\n",
    "\n",
    "for i in random.sample(range(len(X_test)), 5):\n",
    "    plt.figure(figsize=(12,4))\n",
    "    for j in range(X_test.shape[2]):  # plot each sensor channel\n",
    "        plt.plot(X_test[i,:,j], label=f'Sensor {j+1}')\n",
    "    plt.title(f'Gait Wave - Sample {i} | Label: {\"PD\" if y_test[i]==1 else \"Healthy\"}')\n",
    "    plt.xlabel('Time Steps')\n",
    "    plt.ylabel('Normalized Force')\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06caaf9-51c1-49a9-9404-2243d26d650a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#18 images for showing pd vs healthy for all sensors\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Folder path \n",
    "DATA_DIR = \"#folder path\"\n",
    "\n",
    "# List files \n",
    "pd_files = glob.glob(os.path.join(DATA_DIR, \"*Pt*.txt\"))   # Parkinson's\n",
    "healthy_files = glob.glob(os.path.join(DATA_DIR, \"*Co*.txt\"))  # Healthy\n",
    "\n",
    "#  Pick random files\n",
    "pd_file = np.random.choice(pd_files)\n",
    "healthy_file = np.random.choice(healthy_files)\n",
    "print(\"PD File:\", pd_file)\n",
    "print(\"Healthy File:\", healthy_file)\n",
    "\n",
    "#  Load files \n",
    "df_pd = pd.read_csv(pd_file, sep=\"\\t\", header=None).iloc[:, 1:19]\n",
    "df_pd.columns = [f\"FSR_{i+1}\" for i in range(18)]\n",
    "\n",
    "df_healthy = pd.read_csv(healthy_file, sep=\"\\t\", header=None).iloc[:, 1:19]\n",
    "df_healthy.columns = [f\"FSR_{i+1}\" for i in range(18)]\n",
    "\n",
    "#  Plot overlaid signals \n",
    "plt.figure(figsize=(15, 30))\n",
    "\n",
    "for i in range(18):\n",
    "    plt.subplot(9, 2, i+1)\n",
    "    plt.plot(df_pd.iloc[:, i], label=\"PD\", color='r')\n",
    "    plt.plot(df_healthy.iloc[:, i], label=\"Healthy\", color='g', alpha=0.7)\n",
    "    plt.title(f\"Sensor {i+1} - PD vs Healthy\")\n",
    "    plt.xlabel(\"Time steps\")\n",
    "    plt.ylabel(\"Force (N)\")\n",
    "    plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "#red-pd\n",
    "#green-healthy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79233b0b-a390-4227-b394-d23c36de390e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#single image taking average of all sensors\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Average across all sensors\n",
    "pd_avg = df_pd.mean(axis=1)\n",
    "healthy_avg = df_healthy.mean(axis=1)\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.plot(pd_avg, label=\"PD\", color='r')\n",
    "plt.plot(healthy_avg, label=\"Healthy\", color='g', alpha=0.7)\n",
    "plt.title(\"Average Gait Wave - PD vs Healthy\")\n",
    "plt.xlabel(\"Time steps\")\n",
    "plt.ylabel(\"Force (N)\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40360f6-85c5-4b76-aab3-8a6a740fd485",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
